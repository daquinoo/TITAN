{
    "receptor_start_stop_token": true,
    "receptor_padding_length": 50,
    "dense_hidden_sizes": [
        368,
        184
    ],
    "activation_fn": "relu",
    "dropout": 0.5,
    "batch_norm": false,
    "batch_size": 32,
    "lr": 0.0001,
    "receptor_attention_size": 64,
    "epochs": 100,
    "save_model": 25,
    "receptor_embedding_size": 24,
    "receptor_filters": [24, 24, 24],
    "receptor_kernel_sizes": [[3,24], [5,24], [7,24]],
    "receptor_embedding": "predefined",
    "predefined_embedding": "blosum"
}
